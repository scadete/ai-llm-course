{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bTt0jC-0OQW"
      },
      "source": [
        "# Memória\n",
        "\n",
        "Os LLM são essencialmente stateless, isto é não guardam histórico e cada interação é uma nova chamada na API. Cada transação é independente.\n",
        "Chatbots aparentam ter memória porque o código que o implementa considera o histórico de toda conversa no contexto.\n",
        "\n",
        "Langchain oferece diferentes tipos de gerenciadores de memória.\n",
        "Abordaremos desses:\n",
        "- ConversationBufferMemory\n",
        "- ConversationBufferWindowMemory\n",
        "- ConversationTokenBufferMemory\n",
        "- ConversationSummaryMemory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMy4WmXq1grR"
      },
      "source": [
        "## Preparando o Ambiente\n",
        "\n",
        "Para iniciar um trabalho sobre a API da OpenAI, vamos primeiro importar a biblioteca python da openai. Para facilitar o carregamento seguro da chave de API utilizada, também utilizaremos a biblioteca python-dotenv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install openai\n",
        "%pip install --upgrade langchain\n",
        "%pip install langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fLf9EebGJMO",
        "outputId": "46186765-5e9c-49a7-fd55-f5c9fde9e440"
      },
      "outputs": [],
      "source": [
        "# Setup environment and import required libraries\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%set_env OPENAI_API_KEY=#Your API Key here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm_model=\"gpt-3.5-turbo\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationChain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Histórico de Navegação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HadZVTOqubkd"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationBufferMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# To control the randomness and creativity of the generated\n",
        "# text by an LLM, use temperature = 0.0\n",
        "llm = ChatOpenAI(temperature=0.0, model=llm_model)\n",
        "memory = ConversationBufferMemory()\n",
        "conversation = ConversationChain(\n",
        "    llm=llm, \n",
        "    memory = memory,\n",
        "    verbose=True # Esse comando permite ver o que a LLM está aplicando\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conversation.predict(input=\"Oi, me chamo Saulo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conversation.predict(input=\"Qual a resposta para a pergunta sobre o universo e tudo mais?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conversation.predict(input=\"qual meu nome?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A variável memory armazena a memória da conversa até então. Vamos ver seu valor a seguir:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(memory.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se quisermos alterar um conteúdo, dizendo qual o contexto e memória pregresso da uma interação, pode ser definida uma variável nova para isso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "memory = ConversationBufferMemory()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Com uma memória vazia, adicionar os elementos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "memory.save_context(\n",
        "    {\"input\": \"Oi\"},\n",
        "    {\"output\": \"Opa, novidades?\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(memory.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "memory.save_context(\n",
        "    {\"input\": \"Nada demais\"},\n",
        "    {\"output\": \"Massa\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(memory.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Janela de Memória\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
